"""
æ¢¯åº¦ä¿æŒèåˆç‰ˆæœ¬çš„æ•°æ®åˆå¹¶è„šæœ¬
å¯¹æ ‡ 4ALLProcess/MergeCAEandMeasurePoint.py

ä¸»è¦æ”¹è¿›ï¼š
1. ä½¿ç”¨æ¢¯åº¦ä¿æŒèåˆæ›¿ä»£ DAG ä¼ æ’­
2. æ— ç‰‡çŠ¶å‰²è£‚
3. ä¿æŒ CAE æ¢¯åº¦åœºè¿ç»­æ€§
4. æ›´å¿«çš„è®¡ç®—é€Ÿåº¦
5. é›†æˆå¯è§†åŒ–
"""

import torch
import os
import sys

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from fusion_methods import GradientPreservingFusion
from fusion_methods.utils import compute_mesh_metrics, print_metrics
from visualization import FieldVisualizer, create_comparison_plot
import csv
from scipy.io import loadmat
import numpy as np
import time

def MergeCAEandMeasure_GradientFusion(parameters):
    """
    ä½¿ç”¨æ¢¯åº¦ä¿æŒèåˆçš„æ•°æ®åˆå¹¶
    
    å‚æ•°ç»“æ„ï¼ˆä¸åŸç‰ˆç›¸åŒï¼‰:
    {
        "GraphDataPath": å›¾æ•°æ®è·¯å¾„,
        "MeasureDataFile": å®æµ‹æ•°æ®æ–‡ä»¶,
        "SensorInformationFile": ä¼ æ„Ÿå™¨ä¿¡æ¯æ–‡ä»¶,
        "Result_base_save_path": ç»“æœä¿å­˜è·¯å¾„,
        "rms_file_path": CAE RMS æ–‡ä»¶è·¯å¾„,
        "direction": æ–¹å‘ (1/2/3),
        "Config_ID": é…ç½® ID,
        
        # æ–°å¢å‚æ•°
        "lambda_smooth": å¹³æ»‘å¼ºåº¦ï¼ˆé»˜è®¤ 0.1ï¼‰,
        "lambda_grad": æ¢¯åº¦ä¿æŒå¼ºåº¦ï¼ˆé»˜è®¤ 1.0ï¼‰,
        "enable_visualization": æ˜¯å¦ç”Ÿæˆå¯è§†åŒ–ï¼ˆé»˜è®¤ Trueï¼‰
    }
    
    è¿”å›:
    åŒ…å«èåˆç»“æœçš„å­—å…¸
    """
    try:
        print(f"\n{'='*70}")
        print(f"ğŸš€ æ¢¯åº¦ä¿æŒèåˆ - æ•°æ®åˆå¹¶")
        print(f"{'='*70}\n")
        
        total_start = time.time()
        
        # ========== 1. å‚æ•°è§£æ ==========
        GraphDataPath = os.path.normpath(parameters.get("GraphDataPath"))
        MeasureDataFilePath = os.path.normpath(parameters.get("MeasureDataFile"))
        SensorInformationFileCsvPath = os.path.normpath(parameters.get("SensorInformationFile"))
        direction = int(parameters.get("direction", 1))
        Config_ID = parameters.get("Config_ID", "default")
        
        # æ–°å¢å‚æ•°
        lambda_smooth = float(parameters.get("lambda_smooth", 0.1))
        lambda_grad = float(parameters.get("lambda_grad", 1.0))
        enable_viz = parameters.get("enable_visualization", True)
        
        print(f"ğŸ“‚ è¾“å…¥æ–‡ä»¶:")
        print(f"   - å›¾æ•°æ®: {GraphDataPath}")
        print(f"   - å®æµ‹æ•°æ®: {MeasureDataFilePath}")
        print(f"   - ä¼ æ„Ÿå™¨ä¿¡æ¯: {SensorInformationFileCsvPath}")
        print(f"\nâš™ï¸  å‚æ•°:")
        print(f"   - é…ç½® ID: {Config_ID}")
        print(f"   - æ–¹å‘: {direction}")
        print(f"   - Î»_smooth: {lambda_smooth}")
        print(f"   - Î»_grad: {lambda_grad}")
        
        # æ£€æŸ¥æ–‡ä»¶
        for path in [GraphDataPath, MeasureDataFilePath, SensorInformationFileCsvPath]:
            if not os.path.exists(path):
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        
        # ========== 2. åŠ è½½å›¾æ•°æ® ==========
        print(f"\nğŸ“Š åŠ è½½å›¾æ•°æ®...")
        loaded_data = torch.load(GraphDataPath)
        graph_data = loaded_data['graph_data']
        node_id_mapping = loaded_data['node_id_mapping']
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        graph_data = graph_data.to(device)
        
        print(f"   âœ“ èŠ‚ç‚¹æ•°: {graph_data.num_nodes:,}")
        print(f"   âœ“ è¾¹æ•°: {graph_data.num_edges:,}")
        print(f"   âœ“ è®¾å¤‡: {device}")
        
        # ========== 3. è¯»å–å®æµ‹æ•°æ® ==========
        print(f"\nğŸ“¡ è¯»å–å®æµ‹æ•°æ®...")
        measure_data = loadmat(MeasureDataFilePath)
        dataArray_est = measure_data['dataArray_est'].T  # [DOFs, FreqPoints]
        dofs = dataArray_est.shape[0]
        frequency_resolution = measure_data['FrequencyResolution']
        
        # è®¡ç®— RMS
        RMS_Array = np.zeros(dofs)
        for dof in range(dofs):
            rms_value = np.sqrt(np.sum(dataArray_est[dof, :] * frequency_resolution))
            RMS_Array[dof] = rms_value
        
        print(f"   âœ“ DOF æ•°: {dofs}")
        print(f"   âœ“ RMS èŒƒå›´: [{RMS_Array.min():.4e}, {RMS_Array.max():.4e}]")
        
        # ========== 4. è¯»å–ä¼ æ„Ÿå™¨ä¿¡æ¯ ==========
        print(f"\nğŸ“Œ è¯»å–ä¼ æ„Ÿå™¨ä¿¡æ¯...")
        sensor_ids = []
        sensor_node_ids = []
        with open(SensorInformationFileCsvPath, 'r') as f:
            csv_reader = csv.DictReader(f)
            for row in csv_reader:
                sensor_ids.append(row['ID'])
                sensor_node_ids.append(int(row['NodeID']))
        
        print(f"   âœ“ ä¼ æ„Ÿå™¨æ•°é‡: {len(sensor_ids)}")
        print(f"   âœ“ ä¼ æ„Ÿå™¨ ID: {sensor_ids[:5]}..." if len(sensor_ids) > 5 else f"   âœ“ ä¼ æ„Ÿå™¨ ID: {sensor_ids}")
        
        # ========== 5. æå–ä½¿ç”¨çš„ä¼ æ„Ÿå™¨ ==========
        modified_nodes_ids = parameters.get("ModifiedNodesSelectedIds", [])
        if isinstance(modified_nodes_ids, str):
            modified_nodes_ids = modified_nodes_ids.strip('[]').split(',')
            modified_nodes_ids = [id.strip() for id in modified_nodes_ids]
        
        print(f"\nğŸ¯ æœ¬æ¬¡ä½¿ç”¨çš„ä¼ æ„Ÿå™¨: {modified_nodes_ids}")
        
        # è·å–å¯¹åº”çš„èŠ‚ç‚¹ ID å’Œ RMS å€¼
        sensor_values = []
        modified_nodes = []
        for modified_id in modified_nodes_ids:
            try:
                index = sensor_ids.index(modified_id)
                node_id = sensor_node_ids[index]
                rms_index = int(index) * 3 + direction
                rms_value = RMS_Array[rms_index]
                
                modified_nodes.append(node_id - 1)  # èŠ‚ç‚¹ ID è½¬ç´¢å¼•
                sensor_values.append(rms_value)
                
                print(f"   âœ“ {modified_id}: NodeID={node_id}, RMS={rms_value:.4e}")
            except ValueError:
                print(f"   âš ï¸  æœªæ‰¾åˆ°ä¼ æ„Ÿå™¨ {modified_id}")
        
        modified_nodes = torch.tensor(modified_nodes, dtype=torch.long, device=device)
        sensor_values = torch.tensor(sensor_values, dtype=torch.float, device=device)
        
        # ========== 6. ä¿å­˜åŸå§‹ CAE åœºï¼ˆç”¨äºå¯¹æ¯”ï¼‰==========
        x_cae_original = graph_data.y.clone().squeeze()
        
        # ========== 7. åˆå§‹åŒ–æ¢¯åº¦èåˆå™¨ ==========
        print(f"\n{'='*70}")
        print(f"ğŸ”§ åˆå§‹åŒ–æ¢¯åº¦ä¿æŒèåˆå™¨")
        print(f"{'='*70}")
        
        fusion = GradientPreservingFusion(
            edge_index=graph_data.edge_index,
            num_nodes=graph_data.num_nodes,
            device=device
        )
        
        # ========== 8. æ‰§è¡Œèåˆ ==========
        x_fused, info = fusion.fuse(
            x_cae=graph_data.y.squeeze(),
            sensor_indices=modified_nodes,
            sensor_values=sensor_values,
            lambda_smooth=lambda_smooth,
            lambda_grad=lambda_grad,
            max_iter=1000,
            tol=1e-7,
            verbose=True
        )
        
        # æ›´æ–°å›¾æ•°æ®
        graph_data.y = x_fused.unsqueeze(1)
        
        # ========== 9. è®¡ç®—è´¨é‡æŒ‡æ ‡ ==========
        metrics = compute_mesh_metrics(
            field_original=x_cae_original,
            field_fused=x_fused,
            sensor_indices=modified_nodes,
            sensor_values=sensor_values,
            edge_index=graph_data.edge_index
        )
        print_metrics(metrics)
        
        # ========== 10. ä¿å­˜ç»“æœ ==========
        base_save_path = parameters["Result_base_save_path"]
        save_dir = os.path.join(base_save_path, Config_ID)
        os.makedirs(save_dir, exist_ok=True)
        
        print(f"\nğŸ’¾ ä¿å­˜ç»“æœåˆ°: {save_dir}")
        
        # ä¿å­˜èåˆåœº
        y_fused = x_fused.cpu().numpy()
        npy_path = os.path.join(save_dir, "fused_field.npy")
        np.save(npy_path, y_fused)
        print(f"   âœ“ èåˆåœº: {npy_path}")
        
        # ä¿å­˜ä¼ æ„Ÿå™¨æ•°æ®å¯¹æ¯”
        sensor_y_values = [y_fused[node_id-1] for node_id in sensor_node_ids]
        csv_path = os.path.join(save_dir, "sensor_data.csv")
        
        # è¯»å– CAE RMS ç”¨äºå¯¹æ¯”
        db_value = os.path.basename(os.path.dirname(MeasureDataFilePath)).lower().replace("db", "")
        rms_file_path = parameters["rms_file_path"] + f"\\RMS{db_value}dB.csv"
        cae_rms_values = []
        if os.path.exists(rms_file_path):
            with open(rms_file_path, 'r') as f:
                csv_reader = csv.DictReader(f)
                cae_rms_data = {int(row['nodes']): float(row['RMS']) for row in csv_reader}
            
            # ä½¿ç”¨ node_id_mapping å°†åŸå§‹èŠ‚ç‚¹ ID è½¬æ¢ä¸ºå›¾ç´¢å¼•
            # CAE RMS æ–‡ä»¶ä¸­çš„ nodes åˆ—æ˜¯ 1-based çš„å›¾ç´¢å¼•
            for node_id in sensor_node_ids:
                if node_id in node_id_mapping:
                    graph_idx = node_id_mapping[node_id]
                    cae_idx = graph_idx + 1  # CAE æ–‡ä»¶ä½¿ç”¨ 1-based ç´¢å¼•
                    cae_rms_values.append(cae_rms_data.get(cae_idx, 0.0))
                else:
                    cae_rms_values.append(0.0)
        
        # å†™å…¥ CSV
        with open(csv_path, 'w', newline='') as f:
            csv_writer = csv.writer(f)
            csv_writer.writerow(['SensorID', 'NodeID', 'Measured_RMS', 'CAE_RMS', 'Fused_RMS', 'Error'])
            
            for i, (sid, nid) in enumerate(zip(sensor_ids, sensor_node_ids)):
                measured = RMS_Array[3*i+direction]
                cae = cae_rms_values[i] if cae_rms_values else 0.0
                fused = sensor_y_values[i]
                error = abs(fused - measured)
                csv_writer.writerow([sid, nid, f"{measured:.6e}", f"{cae:.6e}", 
                                   f"{fused:.6e}", f"{error:.6e}"])
        
        print(f"   âœ“ ä¼ æ„Ÿå™¨æ•°æ®: {csv_path}")
        
        # ä¿å­˜èåˆä¿¡æ¯
        info_path = os.path.join(save_dir, "fusion_info.txt")
        with open(info_path, 'w') as f:
            f.write(f"æ¢¯åº¦ä¿æŒèåˆä¿¡æ¯\n")
            f.write(f"{'='*50}\n\n")
            f.write(f"é…ç½® ID: {Config_ID}\n")
            f.write(f"ä¼ æ„Ÿå™¨: {modified_nodes_ids}\n\n")
            f.write(f"å‚æ•°:\n")
            f.write(f"  Î»_smooth: {lambda_smooth}\n")
            f.write(f"  Î»_grad: {lambda_grad}\n\n")
            f.write(f"æ±‚è§£ä¿¡æ¯:\n")
            f.write(f"  è¿­ä»£æ¬¡æ•°: {info['iterations']}\n")
            f.write(f"  æœ€ç»ˆæ®‹å·®: {info['residual']:.4e}\n")
            f.write(f"  æ”¶æ•›: {'æ˜¯' if info['converged'] else 'å¦'}\n")
            f.write(f"  æ±‚è§£æ—¶é—´: {info['solve_time']:.2f}ç§’\n")
            f.write(f"  æ€»æ—¶é—´: {info['total_time']:.2f}ç§’\n\n")
            f.write(f"è´¨é‡æŒ‡æ ‡:\n")
            f.write(f"  ä¼ æ„Ÿå™¨æœ€å¤§è¯¯å·®: {metrics['sensor_fit']['fused_max_error']:.4e}\n")
            f.write(f"  ä¼ æ„Ÿå™¨å¹³å‡è¯¯å·®: {metrics['sensor_fit']['fused_mean_error']:.4e}\n")
            f.write(f"  æ¢¯åº¦æ–¹å·®: {metrics['continuity']['fused_gradient_var']:.4e}\n")
        
        print(f"   âœ“ èåˆä¿¡æ¯: {info_path}")
        
        # ========== 11. Visualization ==========
        if enable_viz:
            print(f"\n{'='*70}")
            print(f"Generating Visualization")
            print(f"{'='*70}")
            
            # Read node coordinates
            if 'pos' in graph_data:
                node_coords = graph_data.pos.cpu().numpy()
            elif hasattr(graph_data, 'x') and graph_data.x.shape[1] >= 3:
                node_coords = graph_data.x[:, :3].cpu().numpy()
            else:
                print(f"   Warning: Node coordinates not found, skipping visualization")
                node_coords = None
            
            if node_coords is not None:
                viz_dir = os.path.join(save_dir, "visualizations")
                os.makedirs(viz_dir, exist_ok=True)
                
                visualizer = FieldVisualizer(node_coords)
                
                create_comparison_plot(
                    visualizer=visualizer,
                    field_original=x_cae_original.cpu().numpy(),
                    field_fused=y_fused,
                    sensor_indices=modified_nodes.cpu().numpy(),
                    output_dir=viz_dir,
                    config_id=Config_ID
                )
        
        # ========== 12. æ€»ç»“ ==========
        total_time = time.time() - total_start
        
        print(f"\n{'='*70}")
        print(f"âœ… èåˆå®Œæˆï¼")
        print(f"{'='*70}")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"ğŸ“ ç»“æœè·¯å¾„: {save_dir}")
        print(f"{'='*70}\n")
        
        return {
            'success': True,
            'config_id': Config_ID,
            'fused_field': y_fused,
            'metrics': metrics,
            'info': info,
            'save_dir': save_dir,
            'total_time': total_time
        }
    
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            'success': False,
            'error': str(e)
        }


if __name__ == "__main__":
    # æµ‹è¯•ç¤ºä¾‹
    import sys
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
    
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
    
    parameters = {
        "GraphDataPath": os.path.join(project_root, '1ExperiStep', '1AddCAEData2ConstructGraphData', 'GraphData', 'GraphData.pt'),
        "MeasureDataFile": os.path.join(project_root, '0Data', '1ExperiData', '0dB', 'dataArray_est.mat'),
        "SensorInformationFile": os.path.join(project_root, '0Data', '3MeasurePointInformation', 'measurement_points_AllInfo.csv'),
        "Result_base_save_path": os.path.join(os.path.dirname(__file__), 'FusionResults'),
        "rms_file_path": os.path.join(project_root, '0Data', '0CAEData'),
        "direction": 1,
        "Config_ID": "Test_A1_A2",
        "ModifiedNodesSelectedIds": ["A1", "A2"],
        "lambda_smooth": 0.1,
        "lambda_grad": 1.0,
        "enable_visualization": True
    }
    
    result = MergeCAEandMeasure_GradientFusion(parameters)
    
    if result['success']:
        print(f"\nğŸ‰ æµ‹è¯•æˆåŠŸï¼")
        print(f"æŸ¥çœ‹ç»“æœ: {result['save_dir']}")
    else:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
